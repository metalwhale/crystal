# Use the same base image as `ghcr.io/ggml-org/llama.cpp:light-b4927`
# Ref: https://github.com/ggml-org/llama.cpp/blob/b4927/.devops/cpu.Dockerfile
FROM ubuntu:22.04

RUN apt-get update -y && \
    apt-get install -y curl unzip libgomp1

# Install some prebuilt llama.cpp binaries and libraries to work with .gguf files
RUN cd /tmp && \
    curl https://github.com/ggml-org/llama.cpp/releases/download/b4927/llama-b4927-bin-ubuntu-arm64.zip -L -o llama.zip && \
    unzip ./llama.zip -d ./llama && \
    mv ./llama/build/bin/llama-gguf-split /usr/local/bin/ && \
    mv ./llama/build/bin/lib* /usr/local/lib/ && \
    ldconfig /usr/local/lib/ && \
    rm -rf ./llama.zip ./llama

COPY download_model.sh /usr/local/src/download_model.sh
